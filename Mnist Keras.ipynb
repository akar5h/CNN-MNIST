{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MNIST dataset using Keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import keras \n",
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten\n",
    "from keras.layers import Conv2D, MaxPool2D\n",
    "from keras import backend as K\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 128\n",
    "num_classes = 10\n",
    "epochs=12\n",
    "\n",
    "img_width = 28\n",
    "img_height = 28\n",
    "\n",
    "(x_train , y_train), (x_test, y_test) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We define the batch size of 128 data per epoch. \n",
    "\n",
    "**Batch size** defines the number of samples that going to be propagated through the network at each epoch. It requires less memory and is especially important in case if you are not able to fit dataset in memory. \n",
    "\n",
    "Since MNIST handwritten digits have a input dimension of 28*28, we define image rows and columns as 28, 28."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "requests.packages.urllib3.disable_warnings()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Rearrange the shape of our input data to pass it as input to our convolutional neural network.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape: (60000, 28, 28, 1)\n",
      "60000 train samples\n",
      "10000 test samples\n"
     ]
    }
   ],
   "source": [
    "if K.image_data_format() == 'channels_first':\n",
    "    x_train = x_train.reshape(x_train.shape[0], 1, img_width, img_height)\n",
    "    x_test = x_test.reshape(x_test.shape[0], 1, img_width, img_height)\n",
    "    input_shape = (1, img_width, img_height)\n",
    "else:\n",
    "    x_train = x_train.reshape(x_train.shape[0], img_width, img_height, 1)\n",
    "    x_test = x_test.reshape(x_test.shape[0], img_width, img_height, 1)\n",
    "    input_shape = (img_width, img_height, 1)\n",
    "\n",
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    "x_train /= 255\n",
    "x_test /= 255\n",
    "print('x_train shape:', x_train.shape)\n",
    "print(x_train.shape[0], 'train samples')\n",
    "print(x_test.shape[0], 'test samples')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Neural networks perform much better when the output label is fed as a sparse matrix so we convert the y-label for both train and test data as a sparse matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#convert class vector to binary sparsse matrix\n",
    "y_train = keras.utils.to_categorical(y_train,num_classes)\n",
    "y_test = keras.utils.to_categorical(y_test,num_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model and Design\n",
    "* First we define model to be a sequential model.\n",
    "* We stack **Convolution Layer** and **Pooling Layer** along with **Dropout layer**\n",
    "* Dropout layer provide simple way to overfit data by randomly dropping components of NN\n",
    "* We flatten the layers to one single  dimensional vector\n",
    "* Results in a scenario where at each layer more neurons are forced to learn the multiple characteristics of the neural network. \n",
    "* The last layer of the neural network will have number of node equal to the number of output class i.e. 10 and the activation function we will be using is “softmax”.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/12\n",
      "60000/60000 [==============================] - 33s 549us/step - loss: 0.3583 - acc: 0.8920 - val_loss: 0.1037 - val_acc: 0.9689\n",
      "Epoch 2/12\n",
      "60000/60000 [==============================] - 32s 530us/step - loss: 0.1450 - acc: 0.9568 - val_loss: 0.0656 - val_acc: 0.9796\n",
      "Epoch 3/12\n",
      "60000/60000 [==============================] - 32s 539us/step - loss: 0.1086 - acc: 0.9680 - val_loss: 0.0571 - val_acc: 0.9806\n",
      "Epoch 4/12\n",
      "60000/60000 [==============================] - 34s 560us/step - loss: 0.0925 - acc: 0.9729 - val_loss: 0.0514 - val_acc: 0.9815\n",
      "Epoch 5/12\n",
      "60000/60000 [==============================] - 32s 526us/step - loss: 0.0802 - acc: 0.9755 - val_loss: 0.0477 - val_acc: 0.9827\n",
      "Epoch 6/12\n",
      "60000/60000 [==============================] - 32s 526us/step - loss: 0.0731 - acc: 0.9787 - val_loss: 0.0432 - val_acc: 0.9853\n",
      "Epoch 7/12\n",
      "60000/60000 [==============================] - 32s 531us/step - loss: 0.0671 - acc: 0.9798 - val_loss: 0.0430 - val_acc: 0.9851\n",
      "Epoch 8/12\n",
      "60000/60000 [==============================] - 33s 552us/step - loss: 0.0613 - acc: 0.9813 - val_loss: 0.0400 - val_acc: 0.9855\n",
      "Epoch 9/12\n",
      "60000/60000 [==============================] - 32s 539us/step - loss: 0.0597 - acc: 0.9818 - val_loss: 0.0407 - val_acc: 0.9863\n",
      "Epoch 10/12\n",
      "60000/60000 [==============================] - 32s 530us/step - loss: 0.0558 - acc: 0.9832 - val_loss: 0.0391 - val_acc: 0.9864\n",
      "Epoch 11/12\n",
      "60000/60000 [==============================] - 32s 531us/step - loss: 0.0515 - acc: 0.9839 - val_loss: 0.0406 - val_acc: 0.9865\n",
      "Epoch 12/12\n",
      "60000/60000 [==============================] - 32s 532us/step - loss: 0.0495 - acc: 0.9848 - val_loss: 0.0356 - val_acc: 0.9872\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fc763f45128>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Conv2D(32, kernel_size=(3,3),\n",
    "                activation = 'relu',\n",
    "                input_shape=input_shape))\n",
    "\n",
    "model.add(MaxPool2D(pool_size=(2,2)))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128,activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(num_classes,activation='softmax'))\n",
    "\n",
    "model.compile(loss=keras.losses.categorical_crossentropy, optimizer = keras.optimizers.Adadelta(),metrics=['accuracy'])\n",
    "\n",
    "model.fit(x_train,y_train,batch_size=batch_size,epochs=epochs,verbose=1,validation_data=(x_test,y_test))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss 0.0356181707877884\n",
      "Test accuracy 0.9872\n"
     ]
    }
   ],
   "source": [
    "score = model.evaluate(x_test, y_test, verbose=0)\n",
    "print('Test loss', score[0])\n",
    "print('Test accuracy', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
